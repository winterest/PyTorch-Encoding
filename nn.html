


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>encoding.nn &mdash; Encoding master documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="encoding.parallel" href="parallel.html" />
    <link rel="prev" title="Deep TEN: Deep Texture Encoding Network Example" href="tutorials/texture.html" /> 


  <script type="text/javascript" src="../_static/js/hidebib.js"></script>    


  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>



<div class="container-fluid header-holder" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://hangzhang.org/" aria-label="Hang Zhang"></a>
      <!--a class="navbar-brand" href="https://hangzhang.org/" aria-label="Hang Zhang">
          <img style="max-width:50px" src="https://hangzhang.org//files/favicon.png">
      </a-->

      <div class="main-menu">
        <ul>
          <li> <a href="https://hangzhang.org/"><span class="fa fa-home"></span> Home</a></li>
          <li> <a href="https://hangzhang.org//#publication"><span class="fa fa-book"></span> Publications</a></li>
          <li> <a href="https://hangzhang.org//blog/"><span class="fa fa-pencil"></span> Blog</a></li>
          <li> <a href="https://hangzhang.org//PyTorch-Encoding/"><span class="fa fa-tasks"></span> Toolkit</a></li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<!--div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <div class="ecosystem-dropdown">
              <a id="dropdownMenuButton" data-toggle="ecosystem-dropdown">
                Ecosystem
              </a>
              <div class="ecosystem-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/hub"">
                  <span class=dropdown-title>Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class=dropdown-title>Tools & Libraries</span>
                  <p>Explore the ecosystem of tools and libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <div class="resources-dropdown">
              <a id="resourcesDropdownButton" data-toggle="resources-dropdown">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/resources"">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class=dropdown-title>About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div-->


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master (1.2.1b20200629)
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/compile.html">Install and Citations</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model_zoo/imagenet.html">Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo/segmentation.html">Semantic Segmentation</a></li>
</ul>
<p class="caption"><span class="caption-text">Other Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/cifar.html">EncNet on CIFAR-10</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/style.html">MSG-Net Style Transfer Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/syncbn.html">Implementing Synchronized Multi-GPU Batch Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/texture.html">Deep TEN: Deep Texture Encoding Network Example</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">encoding.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="parallel.html">encoding.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">encoding.utils</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>encoding.nn</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/nn.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="encoding-nn">
<h1>encoding.nn<a class="headerlink" href="#encoding-nn" title="Permalink to this headline">¶</a></h1>
<p>Customized NN modules in Encoding Package. For Synchronized Cross-GPU Batch Normalization, please visit <a class="reference internal" href="#encoding.nn.BatchNorm2d" title="encoding.nn.BatchNorm2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoding.nn.BatchNorm2d</span></code></a>.</p>
<div class="section" id="encoding">
<h2><span class="hidden-section">Encoding</span><a class="headerlink" href="#encoding" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="encoding.nn.Encoding">
<em class="property">class </em><code class="sig-prename descclassname">encoding.nn.</code><code class="sig-name descname">Encoding</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">D</span></em>, <em class="sig-param"><span class="n">K</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/encoding.html#Encoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.Encoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Encoding Layer: a learnable residual encoder.</p>
<a class="reference internal image-reference" href="_images/cvpr17.svg"><img alt="_images/cvpr17.svg" class="align-center" src="_images/cvpr17.svg" width="30%" /></a>
<p>Encoding Layer accpets 3D or 4D inputs.
It considers an input featuremaps with the shape of <span class="math notranslate nohighlight">\(C\times H\times W\)</span>
as a set of C-dimentional input features <span class="math notranslate nohighlight">\(X=\{x_1, ...x_N\}\)</span>, where N is total number
of features given by <span class="math notranslate nohighlight">\(H\times W\)</span>, which learns an inherent codebook
<span class="math notranslate nohighlight">\(D=\{d_1,...d_K\}\)</span> and a set of smoothing factor of visual centers
<span class="math notranslate nohighlight">\(S=\{s_1,...s_K\}\)</span>. Encoding Layer outputs the residuals with soft-assignment weights
<span class="math notranslate nohighlight">\(e_k=\sum_{i=1}^Ne_{ik}\)</span>, where</p>
<div class="math notranslate nohighlight">
\[e_{ik} = \frac{exp(-s_k\|r_{ik}\|^2)}{\sum_{j=1}^K exp(-s_j\|r_{ij}\|^2)} r_{ik}\]</div>
<p>and the residuals are given by <span class="math notranslate nohighlight">\(r_{ik} = x_i - d_k\)</span>. The output encoders are
<span class="math notranslate nohighlight">\(E=\{e_1,...e_K\}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>D</strong> – dimention of the features or feature channels</p></li>
<li><p><strong>K</strong> – number of codeswords</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\(X\in\mathcal{R}^{B\times N\times D}\)</span> or
<span class="math notranslate nohighlight">\(\mathcal{R}^{B\times D\times H\times W}\)</span> (where <span class="math notranslate nohighlight">\(B\)</span> is batch,
<span class="math notranslate nohighlight">\(N\)</span> is total number of features or <span class="math notranslate nohighlight">\(H\times W\)</span>.)</p></li>
<li><p>Output: <span class="math notranslate nohighlight">\(E\in\mathcal{R}^{B\times K\times D}\)</span></p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>codewords</strong> (<em>Tensor</em>) – the learnable codewords of shape (<span class="math notranslate nohighlight">\(K\times D\)</span>)</p></li>
<li><p><strong>scale</strong> (<em>Tensor</em>) – the learnable scale factor of visual centers</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Reference:</dt><dd><p>Hang Zhang, Kristin Dana, Jianping Shi, Zhongyue Zhang, Xiaogang Wang, Ambrish Tyagi,
Amit Agrawal. “Context Encoding for Semantic Segmentation.
<em>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2018</em></p>
<p>Hang Zhang, Jia Xue, and Kristin Dana. “Deep TEN: Texture Encoding Network.”
<em>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017</em></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">encoding</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="p">,</span><span class="n">C</span><span class="p">,</span><span class="n">H</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">K</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">DoubleTensor</span><span class="p">(</span><span class="n">B</span><span class="p">,</span><span class="n">C</span><span class="p">,</span><span class="n">H</span><span class="p">,</span><span class="n">W</span><span class="p">)</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span> <span class="o">=</span> <span class="n">encoding</span><span class="o">.</span><span class="n">Encoding</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">K</span><span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">E</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="encoding.nn.Encoding.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/encoding.html#Encoding.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.Encoding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="distsyncbatchnorm">
<h2><span class="hidden-section">DistSyncBatchNorm</span><a class="headerlink" href="#distsyncbatchnorm" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="encoding.nn.DistSyncBatchNorm">
<em class="property">class </em><code class="sig-prename descclassname">encoding.nn.</code><code class="sig-name descname">DistSyncBatchNorm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">num_features</span></em>, <em class="sig-param"><span class="n">eps</span><span class="o">=</span><span class="default_value">1e-05</span></em>, <em class="sig-param"><span class="n">momentum</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">process_group</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/syncbn.html#DistSyncBatchNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.DistSyncBatchNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Cross-GPU Synchronized Batch normalization (SyncBN)</p>
<p>Standard BN <a class="footnote-reference brackets" href="#id3" id="id1">1</a> implementation only normalize the data within each device (GPU).
SyncBN normalizes the input within the whole mini-batch.
We follow the sync-onece implmentation described in the paper <a class="footnote-reference brackets" href="#id4" id="id2">2</a> .
Please see the design idea in the <a class="reference external" href="./notes/syncbn.html">notes</a>.</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - mean[x]}{ \sqrt{Var[x] + \epsilon}} * gamma + beta\]</div>
<p>The mean and standard-deviation are calculated per-channel over
the mini-batches and gamma and beta are learnable parameter vectors
of size C (where C is the input size).</p>
<p>During training, this layer keeps a running estimate of its computed mean
and variance. The running sum is kept with a default momentum of 0.1.</p>
<p>During evaluation, this running mean/variance is used for normalization.</p>
<p>Because the BatchNorm is done over the <cite>C</cite> dimension, computing statistics
on <cite>(N, H, W)</cite> slices, it’s common terminology to call this Spatial BatchNorm</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> – num_features from an expected input of
size batch_size x num_features x height x width</p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability.
Default: 1e-5</p></li>
<li><p><strong>momentum</strong> – the value used for the running_mean and running_var
computation. Default: 0.1</p></li>
<li><p><strong>sync</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, synchronize across
different gpus. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>activation</strong> – str
Name of the activation functions, one of: <cite>leaky_relu</cite> or <cite>none</cite>.</p></li>
<li><p><strong>slope</strong> – float
Negative slope for the <cite>leaky_relu</cite> activation.</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((N, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> (same shape as input)</p></li>
</ul>
</dd>
<dt>Reference:</dt><dd><dl class="footnote brackets">
<dt class="label" id="id3"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id5">2</a>)</span></dt>
<dd><p>Ioffe, Sergey, and Christian Szegedy. “Batch normalization: Accelerating deep network training by reducing internal covariate shift.” <em>ICML 2015</em></p>
</dd>
<dt class="label" id="id4"><span class="brackets">2</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id6">2</a>)</span></dt>
<dd><p>Hang Zhang, Kristin Dana, Jianping Shi, Zhongyue Zhang, Xiaogang Wang, Ambrish Tyagi, and Amit Agrawal. “Context Encoding for Semantic Segmentation.” <em>CVPR 2018</em></p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">DistSyncBatchNorm</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="encoding.nn.DistSyncBatchNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/syncbn.html#DistSyncBatchNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.DistSyncBatchNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="syncbatchnorm">
<h2><span class="hidden-section">SyncBatchNorm</span><a class="headerlink" href="#syncbatchnorm" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="encoding.nn.SyncBatchNorm">
<em class="property">class </em><code class="sig-prename descclassname">encoding.nn.</code><code class="sig-name descname">SyncBatchNorm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">num_features</span></em>, <em class="sig-param"><span class="n">eps</span><span class="o">=</span><span class="default_value">1e-05</span></em>, <em class="sig-param"><span class="n">momentum</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">sync</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">activation</span><span class="o">=</span><span class="default_value">'none'</span></em>, <em class="sig-param"><span class="n">slope</span><span class="o">=</span><span class="default_value">0.01</span></em>, <em class="sig-param"><span class="n">inplace</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/syncbn.html#SyncBatchNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.SyncBatchNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Cross-GPU Synchronized Batch normalization (SyncBN)</p>
<p>Standard BN <a class="footnote-reference brackets" href="#id3" id="id5">1</a> implementation only normalize the data within each device (GPU).
SyncBN normalizes the input within the whole mini-batch.
We follow the sync-onece implmentation described in the paper <a class="footnote-reference brackets" href="#id4" id="id6">2</a> .
Please see the design idea in the <a class="reference external" href="./notes/syncbn.html">notes</a>.</p>
<div class="math notranslate nohighlight">
\[y = \frac{x - mean[x]}{ \sqrt{Var[x] + \epsilon}} * gamma + beta\]</div>
<p>The mean and standard-deviation are calculated per-channel over
the mini-batches and gamma and beta are learnable parameter vectors
of size C (where C is the input size).</p>
<p>During training, this layer keeps a running estimate of its computed mean
and variance. The running sum is kept with a default momentum of 0.1.</p>
<p>During evaluation, this running mean/variance is used for normalization.</p>
<p>Because the BatchNorm is done over the <cite>C</cite> dimension, computing statistics
on <cite>(N, H, W)</cite> slices, it’s common terminology to call this Spatial BatchNorm</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> – num_features from an expected input of
size batch_size x num_features x height x width</p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability.
Default: 1e-5</p></li>
<li><p><strong>momentum</strong> – the value used for the running_mean and running_var
computation. Default: 0.1</p></li>
<li><p><strong>sync</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, synchronize across
different gpus. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>activation</strong> – str
Name of the activation functions, one of: <cite>leaky_relu</cite> or <cite>none</cite>.</p></li>
<li><p><strong>slope</strong> – float
Negative slope for the <cite>leaky_relu</cite> activation.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((N, C, H, W)\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((N, C, H, W)\)</span> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">SyncBatchNorm</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># for Inpace ABN</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ABN</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">SyncBatchNorm</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;leaky_relu&#39;</span><span class="p">,</span> <span class="n">slope</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="encoding.nn.SyncBatchNorm.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/syncbn.html#SyncBatchNorm.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.SyncBatchNorm.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="py method">
<dt id="encoding.nn.SyncBatchNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/syncbn.html#SyncBatchNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.SyncBatchNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="batchnorm1d">
<h2><span class="hidden-section">BatchNorm1d</span><a class="headerlink" href="#batchnorm1d" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="encoding.nn.BatchNorm1d">
<em class="property">class </em><code class="sig-prename descclassname">encoding.nn.</code><code class="sig-name descname">BatchNorm1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/syncbn.html#BatchNorm1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.BatchNorm1d" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>BatchNorm1d is deprecated in favor of <a class="reference internal" href="#encoding.nn.SyncBatchNorm" title="encoding.nn.SyncBatchNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoding.nn.SyncBatchNorm</span></code></a>.</p>
</div>
</dd></dl>

</div>
<div class="section" id="batchnorm2d">
<h2><span class="hidden-section">BatchNorm2d</span><a class="headerlink" href="#batchnorm2d" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="encoding.nn.BatchNorm2d">
<em class="property">class </em><code class="sig-prename descclassname">encoding.nn.</code><code class="sig-name descname">BatchNorm2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/syncbn.html#BatchNorm2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.BatchNorm2d" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>BatchNorm2d is deprecated in favor of <a class="reference internal" href="#encoding.nn.SyncBatchNorm" title="encoding.nn.SyncBatchNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoding.nn.SyncBatchNorm</span></code></a>.</p>
</div>
</dd></dl>

</div>
<div class="section" id="batchnorm3d">
<h2><span class="hidden-section">BatchNorm3d</span><a class="headerlink" href="#batchnorm3d" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="encoding.nn.BatchNorm3d">
<em class="property">class </em><code class="sig-prename descclassname">encoding.nn.</code><code class="sig-name descname">BatchNorm3d</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/syncbn.html#BatchNorm3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.BatchNorm3d" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>BatchNorm3d is deprecated in favor of <a class="reference internal" href="#encoding.nn.SyncBatchNorm" title="encoding.nn.SyncBatchNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">encoding.nn.SyncBatchNorm</span></code></a>.</p>
</div>
</dd></dl>

</div>
<div class="section" id="inspiration">
<h2><span class="hidden-section">Inspiration</span><a class="headerlink" href="#inspiration" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="encoding.nn.Inspiration">
<em class="property">class </em><code class="sig-prename descclassname">encoding.nn.</code><code class="sig-name descname">Inspiration</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">C</span></em>, <em class="sig-param"><span class="n">B</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/encoding.html#Inspiration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.Inspiration" title="Permalink to this definition">¶</a></dt>
<dd><p>Inspiration Layer (CoMatch Layer) enables the multi-style transfer in feed-forward
network, which learns to match the target feature statistics during the training.
This module is differentialble and can be inserted in standard feed-forward network
to be learned directly from the loss function without additional supervision.</p>
<div class="math notranslate nohighlight">
\[Y = \phi^{-1}[\phi(\mathcal{F}^T)W\mathcal{G}]\]</div>
<p>Please see the <a class="reference external" href="./experiments/style.html">example of MSG-Net</a>
training multi-style generative network for real-time transfer.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Hang Zhang and Kristin Dana. “Multi-style Generative Network for Real-time Transfer.”
<em>arXiv preprint arXiv:1703.06953 (2017)</em></p>
</dd>
</dl>
<dl class="py method">
<dt id="encoding.nn.Inspiration.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/encoding.html#Inspiration.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.Inspiration.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="upsampleconv2d">
<h2><span class="hidden-section">UpsampleConv2d</span><a class="headerlink" href="#upsampleconv2d" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="encoding.nn.UpsampleConv2d">
<em class="property">class </em><code class="sig-prename descclassname">encoding.nn.</code><code class="sig-name descname">UpsampleConv2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">in_channels</span></em>, <em class="sig-param"><span class="n">out_channels</span></em>, <em class="sig-param"><span class="n">kernel_size</span></em>, <em class="sig-param"><span class="n">stride</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">padding</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">dilation</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">groups</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">scale_factor</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/encoding.html#UpsampleConv2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.UpsampleConv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>To avoid the checkerboard artifacts of standard Fractionally-strided Convolution,
we adapt an integer stride convolution but producing a <span class="math notranslate nohighlight">\(2\times 2\)</span> outputs for
each convolutional window.</p>
<a class="reference internal image-reference" href="_images/upconv.png"><img alt="_images/upconv.png" class="align-center" src="_images/upconv.png" style="width: 50%;" /></a>
<dl class="simple">
<dt>Reference:</dt><dd><p>Hang Zhang and Kristin Dana. “Multi-style Generative Network for Real-time Transfer.”
<em>arXiv preprint arXiv:1703.06953 (2017)</em></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<em>int</em>) – Number of channels in the input image</p></li>
<li><p><strong>out_channels</strong> (<em>int</em>) – Number of channels produced by the convolution</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em> or </em><em>tuple</em>) – Size of the convolving kernel</p></li>
<li><p><strong>stride</strong> (<em>int</em><em> or </em><em>tuple</em><em>, </em><em>optional</em>) – Stride of the convolution. Default: 1</p></li>
<li><p><strong>padding</strong> (<em>int</em><em> or </em><em>tuple</em><em>, </em><em>optional</em>) – Zero-padding added to both sides of the input. Default: 0</p></li>
<li><p><strong>output_padding</strong> (<em>int</em><em> or </em><em>tuple</em><em>, </em><em>optional</em>) – Zero-padding added to one side of the output.
Default: 0</p></li>
<li><p><strong>groups</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of blocked connections from input channels to output
channels. Default: 1</p></li>
<li><p><strong>bias</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, adds a learnable bias to the output. Default: True</p></li>
<li><p><strong>dilation</strong> (<em>int</em><em> or </em><em>tuple</em><em>, </em><em>optional</em>) – Spacing between kernel elements. Default: 1</p></li>
<li><p><strong>scale_factor</strong> (<em>int</em>) – scaling factor for upsampling convolution. Default: 1</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span></p></li>
<li><p>Output: <span class="math notranslate nohighlight">\((N, C_{out}, H_{out}, W_{out})\)</span> where
<span class="math notranslate nohighlight">\(H_{out} = scale * (H_{in} - 1) * stride[0] - 2 * padding[0] + kernel\_size[0] + output\_padding[0]\)</span>
<span class="math notranslate nohighlight">\(W_{out} = scale * (W_{in} - 1) * stride[1] - 2 * padding[1] + kernel\_size[1] + output\_padding[1]\)</span></p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weight</strong> (<em>Tensor</em>) – the learnable weights of the module of shape
(in_channels, scale * scale * out_channels, kernel_size[0], kernel_size[1])</p></li>
<li><p><strong>bias</strong> (<em>Tensor</em>) – the learnable bias of the module of shape (scale * scale * out_channels)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With square kernels and equal stride</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UpsampleCov2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># non-square kernels and unequal stride and with padding</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UpsampleCov2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># exact output size can be also specified as an argument</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">downsample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">upsample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UpsampleCov2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h</span> <span class="o">=</span> <span class="n">downsample</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([1, 16, 6, 6])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">upsample</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([1, 16, 12, 12])</span>
</pre></div>
</div>
<dl class="py method">
<dt id="encoding.nn.UpsampleConv2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/encoding.html#UpsampleConv2d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.UpsampleConv2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="grammatrix">
<h2><span class="hidden-section">GramMatrix</span><a class="headerlink" href="#grammatrix" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="encoding.nn.GramMatrix">
<em class="property">class </em><code class="sig-prename descclassname">encoding.nn.</code><code class="sig-name descname">GramMatrix</code><a class="reference internal" href="_modules/encoding/nn/customize.html#GramMatrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.GramMatrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Gram Matrix for a 4D convolutional featuremaps as a mini-batch</p>
<div class="math notranslate nohighlight">
\[\mathcal{G} = \sum_{h=1}^{H_i}\sum_{w=1}^{W_i} \mathcal{F}_{h,w}\mathcal{F}_{h,w}^T\]</div>
<dl class="py method">
<dt id="encoding.nn.GramMatrix.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">y</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/encoding/nn/customize.html#GramMatrix.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#encoding.nn.GramMatrix.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="parallel.html" class="btn btn-neutral float-right" title="encoding.parallel" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="tutorials/texture.html" class="btn btn-neutral" title="Deep TEN: Deep Texture Encoding Network Example" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Hang Zhang.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
    

  <!--  -->

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">encoding.nn</a><ul>
<li><a class="reference internal" href="#encoding"><span class="hidden-section">Encoding</span></a></li>
<li><a class="reference internal" href="#distsyncbatchnorm"><span class="hidden-section">DistSyncBatchNorm</span></a></li>
<li><a class="reference internal" href="#syncbatchnorm"><span class="hidden-section">SyncBatchNorm</span></a></li>
<li><a class="reference internal" href="#batchnorm1d"><span class="hidden-section">BatchNorm1d</span></a></li>
<li><a class="reference internal" href="#batchnorm2d"><span class="hidden-section">BatchNorm2d</span></a></li>
<li><a class="reference internal" href="#batchnorm3d"><span class="hidden-section">BatchNorm3d</span></a></li>
<li><a class="reference internal" href="#inspiration"><span class="hidden-section">Inspiration</span></a></li>
<li><a class="reference internal" href="#upsampleconv2d"><span class="hidden-section">UpsampleConv2d</span></a></li>
<li><a class="reference internal" href="#grammatrix"><span class="hidden-section">GramMatrix</span></a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/language_data.js"></script>
         <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <!--div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div-->

  <!--footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

        </div>
      </div>
    </div>
  </footer-->
  <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <!--div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div-->
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>